\documentclass[10pt]{elsarticle}
%\documentclass[3p,times]{elsarticle}
%\documentclass[review]{elsarticle}
\usepackage{booktabs}
\usepackage[scale=2]{ccicons}
\usepackage{pgfplots}
\usepackage{xspace}
\usepackage{latexsym,amsmath,amssymb,amsfonts,epsfig}
\usepackage{ragged2e}
\usepackage[nooneline]{subfigure}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{tabularx}
\usepackage[flushleft]{threeparttable}
\usepackage{eqnarray,amsmath}
\usepackage{calrsfs}
\usepackage{stackrel}
\usepackage{algorithm}
\usepackage[nooneline]{subfigure}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{tabularx}
\usepackage[flushleft]{threeparttable}
\usepackage{url}
\usepackage{graphicx}
\usepackage{adjustbox}
\usepackage{epstopdf}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[english]{babel}
\usepackage[applemac]{inputenc}
\usepackage{mathptmx}
\usepackage[flushleft]{threeparttable}
\usepackage[font=small,skip=3pt]{caption}
\usepackage{url}
\usepackage{xcolor}
\usepackage{caption}
\usepackage{algorithmic,algorithm}
\usepackage{multirow,multicol}
\usepackage{tikz}
\usepackage{enumitem}
\usetikzlibrary{datavisualization}
\usetikzlibrary{datavisualization.formats.functions}
\usetikzlibrary{calc}
\usepackage{pgf-umlsd}
\usepackage{moreverb}
\usepackage{fix-cm}
%\usepackage{hyperref}
\usepackage{soul}
\newcommand{\hll}[1]{\colorbox{yellow}{$\displaystyle #1$}}

\makeatletter
\DeclareMathAlphabet{\pazocal}{OMS}{zplm}{m}{n}
\usepackage[margin=1 in]{geometry}
\newcommand\xleftrightarrow[2][]{%
\ext@arrow 9999{\longleftrightarrowfill@}{#1}{#2}}
\newcommand\longleftrightarrowfill@{%

\arrowfill@\leftarrow\relbar\rightarrow}
\makeatother

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{rem}{Remarks}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document}
\begin{frontmatter}
\title{Collision Resistant Hash Functions on Lattices}

\author{Nimish Mishra$^{1}$, SK Hafizul Islam$^{1,*}$, Daya Sagar Gupta$^{2}$, Sherali Zeadally$^{3}$}
\address{$^{1}$\emph{Department of Computer Science and Engineering, Indian Institute of Information Technology Kalyani, West Bengal~741235, India}\\
$^{2}$\emph{Department of Computer Science and Engineering, Shershah College of Engineering Sasaram, Bihar 821308, India}\\
$^{3}$\emph{College of Communication and Information, University of Kentucky Lexington, KY, USA 40506}\\
{neelam.nimish@gmail.com, hafi786@gmail.com,
dayasagar.ism@gmail.com, szeadally@uky.edu}}
\cortext[cor1]{Corresponding author. (SK Hafizul Islam)}


\begin{abstract}
 Hash functions have been centers of interest in cryptography because of their \textit{hard to invert} nature, allowing information to be converted to indecipherable formats. However, all previous constructions of hash functions (and other cryptographic primitives) face the threat of being broken by the recent advancements in quantum technology and algorithms. The focus has thus shifted to developing cryptographic primitives on mathematical structures that are, in general, intractable by even quantum algorithms, and lattices are one of them. In this paper, we have reviewed advancements in developing hash functions based on the intractability assumption of the related mathematical problems on lattices. Of independent interest to the reader can be the techniques employed in the underlying reductions of these constructions.
\begin{keyword}
Hash function; Lattice; Worst-case hardness assumption; Shortest
vector problem, Closest vector problem.
\end{keyword}
\end{abstract}
\end{frontmatter}

\section{Introduction}
With the rise of quantum algorithms and the steady advancement made
in constructing practical quantum devices and simulators, efforts
have been put into designing cryptographic primitives that are
secure even under quantum attacks. We assume that the quantum
algorithms can take advantage of superposition, entanglement, and
other purely quantum phenomena that can process information faster,
to up to non-negligible speedups, than their classical
counterparts). One such basis of such constructions is lattice-based
constructions. The use of lattices as the base for constructing
cryptographic primitives received huge interests since the beginning
of this century, starting from Ajtai's seminal paper
\cite{CRHF_Ajtai1996} detailing ways to establish the security of
lattice-based primitives.

Lattices have been studied extensively and independently among the
cryptographic research communities, and the lack of algorithms
attacking mathematical problems on lattices conjectures their
hardness. One of the finest of such algorithms is the LLL
(Lenstra-Lenstra-Lov{\`a}sz) \cite{LLL} algorithm, which is a
lattice-based reduction algorithm and its improved versions- achieve
exponential approximation factors to lattice problems when running
in polynomial time. Moreover, no polynomial-time bounded algorithm
exists that can approximate lattice problems within linear factors
in the rank of a lattice, for a large value of the rank. Such
conjectures solidify the use of lattices in cryptography. However,
lattices suffer from a shortcoming that lattice-based constructions
allow less structure than their number-theoretic counterparts. For
instance, lattice-based hash functions have domains that are subsets
of rings and are neither closed under addition nor multiplication.
Number-theoretic hash functions, on the other hand, have rings as
domains. Quantum algorithms to solve the integer factorization and
discrete logarithm problems \cite{CRHF_Shor1997} are inefficient on
lattice-based constructions because of this very constrained
structure. On the other hand, this constrained structure increases
the difficulty in developing lattice-based primitives.

Ajtai's work \cite{CRHF_Ajtai1996} was the first breakthrough in the
attempts to establish the security of lattice-based primitives on
\textit{worst-case} hardness assumption of lattice problems.
Worst-case hardness assumption is theoretically safer than an
average-case hardness assumption, primarily of experimental evidence
than algorithms can sometimes perform better on certain random
instances, even if the problem is provably secure on the
average-case scenario. Extreme caution is then needed to disqualify
choices of parameters that make the construction tractable on an
average-case situation. The worst-case hardness assumption is based
on the intractability of \textit{any} instance of the problem,
making it probably more secure than average-case hardness
assumption. Thus, when Ajtai demonstrated the relation between an
average-case hardness assumption to a worst-case reduction for
lattice-based constructions, the interest of the research community
sprung up. \textcolor{red}{Informally, standard proof techniques
involve a series of reductions to convert a hard problem into a
number of other cryptographic constructions: Hard problem $\leq$
collision-resistant hash functions $\leq$ one-time signature $\leq$
identity-based scheme $\leq$ signature, where $\leq$ denotes
reduction. This is not clear. Make it clear}

In this paper, we described many collision-resistant hash functions
based on the worst-case hardness assumption of lattice problems. We
review the existing literature that constructs lattice-based hash
functions and provide a brief discussion on correctness, the
underlying hard problems, optimal parameter choices, weaknesses if
any, and reduction techniques applied.

\subsection{Organization of the paper}
The remaining part of the article is arranged as follows.
Section~\ref{L2} gives a brief description of the concept of
lattices and some computational problems on them. Section~\ref{L3}
includes the definition, security notions, and the adversarial model
of a LB-ID-2PAKA protocol. Section~\ref{L4} gives a detail
description of our LB-ID-2PAKA protocol. Section~\ref{L5} presents a
formal security analysis of our LB-ID-2PAKA protocol.
Section~\ref{L6} gives the analysis of computation and communication
costs of our LB-ID-2PAKA protocol and compares these costs with a
relevant, recently proposed LB-2PAKA protocol. Section~\ref{L7}
makes some concluding remarks on the proposed protocol.

\section{Preliminaries}
We indicate $n$ as the security parameter, the prime number $q\in
\mathbb{Z}$ as modulus, a capital bold letter (e.g.,
$\mbox{\textbf{A}}$) as matrix, $\mbox{\textbf{A}}^{\mbox{T}}$ is
the transpose of $\mbox{\textbf{A}}$, a small bold letter (e,g.,
$\mbox{\textbf{x}}$) as a column vector, and
$\parallel\mbox{\textbf{x}}\parallel_{2} = \sqrt{x^{2}_{1} +
x^{2}_{2} + \cdots + x^{2}_{n}}$ is the $L_{2}$ norm (Euclidean
norm) of a vector $\mbox{\textbf{x}} = (x_{1}, x_{2}, \cdots,
x_{n})\in\mathbb{R}^{n}$. We also denote $a\leftarrow_{R}X$ to
signify that $a$ is selected uniformly at random from the set $X$.

\begin{table}[h] \centering \caption{Notations used in
the paper} \label{tab1} \scalebox{1}{
\begin{tabular}{|l|l|}
\hline
\textbf{Notation}    & \textbf{Meaning}\\
\hline
%$\mathbf{x}$, $\mathbf{a}$ etc. & bold faced, lower-case English alphabets represent vectors\\
%\hline
%$\mathbf{A}$, $\mathbf{B}$ etc. & bold faced, upper-case English alphabets represent matrices\\
%\hline
$\mathbb{R}$ & Set of real numbers \\
\hline
$\mathbb{Z}$ & Set of integers \\
\hline
$\mathbb{N}$ & Set of natural numbers \\
\hline
$\pazocal{R}$ & Ring \\
\hline
$\pazocal{L}(\mathbf{B})$ & Lattice \\
\hline
$\mathbf{B}$   & Basis matrix of $\pazocal{L}(\mathbf{B})$ \\
\hline
$\mathbb{{R}}^{n}$ & Euclidean space of $n$-dimension\\
\hline
$n$           & Dimension of a lattice\\
\hline
$m$           & Rank of a lattice \\
\hline
$\pazocal{H}$ & A hash function family \\
\hline
$q$           & Security parameter \\
\hline
$det(\mathbf{A}$) & Determinant of the matrix $\mathbf{A}$ \\
\hline
$\mathbf{A}^{T}$ & Transpose of the matrix $\mathbf{A}$ \\
\hline
$\mathbf{A}^{-1}$ & Inverse of the matrix $\mathbf{A}$ \\
\hline
\end{tabular}}
\end{table}

\subsection{Integer lattice}
Integer lattices are considered as discrete subsets of the
$n$-dimensional Euclidean space $\mathbb{{R}}^{n}$. Formally, given
a set of $m$ linearly independent vectors in $\mathbb{{R}}^{n}$, say
$\{ \mathbf{b_{1}}, \, \mathbf{b_{2}}, \, \mathbf{b_{3}}, \, \cdots,
\, \mathbf{b_{m}} \}$, arranged as columns of a matrix $\mathbf{B}
\, = \, [\mathbf{b_{1}}, \, \mathbf{b_{2}}, \, \mathbf{b_{3}}, \,
\cdots, \, \mathbf{b_{m}}]$ such that $\mathbf{B} \, \in
\mathbb{R}^{n \times m}$, the integer lattice
$\pazocal{L}(\mathbf{B}) \, \subseteq \mathbb{R}^{n}$ is defined as
the set $\pazocal{L}(\mathbf{B})\, = \{ \,
\sum_{i=1}^{m}x_{i}\mathbf{b}_{i}: \, x_{i} \, \in \, \mathbb{Z}
\}$, or equivalently,  $\pazocal{L}(\mathbf{B})\, = \{ \, \mathbf{B}
\mathbf{x}: \, x \, \in \, \mathbb{Z}^{m} \}$ for the usual
matrix-vector multiplication. The integers $m$ and $n$ signify the
\emph{rank} and \emph{dimension} of $\pazocal{L}(\mathbf{B})$. The
matrix $\mathbf{B}$ is defined as the basis of
$\pazocal{L}(\mathbf{B})$. From a computational point of view, the
underlying assumption is that $\mathbf{B}$ has rational coordinates;
every such rational matrix can be converted into an integer matrix
by multiplying by a suitable scaling factor. Without loss of
generality, integer matrices are thus considered as the basis
matrices throughout the paper.

\begin{definition}[Half-open parallelepiped]
\normalfont Given a basis matrix $\mathbf{B} \, \in \, \mathbb{Z}^{n
\times m}$, the half-open parallelepiped for a lattice
$\pazocal{L}(\mathbf{B})$ is defined as $\pazocal{P}(\mathbf{B}) \,
= \, \{\mathbf{B}\mathbf{x}: \, 0 \, \leq \, x_{i} \, < \, 1 \}$.
\end{definition}

$P(B)$ intuitively describes the smallest \textit{unit} of lattice that is repeated over the entire space rendering the lattice its periodic structure.

\begin{lemma}
\normalfont An arbitrarily defined matrix $\mathbf{B} \, \in \,
\mathbb{Z}^{n \times m}$ is a basis for the lattice
$\pazocal{L}(\mathbf{B})$ if and only if the half-open
parallelepiped $\pazocal{P}(\mathbf{B})$ for
$\pazocal{L}(\mathbf{B})$ contains no other lattice point except the
origin.
\end{lemma}

An integer lattice can have several bases, each of which creates a different fundamental parallelepiped while spanning the same set of discrete lattice points.

\begin{definition}[Equivalent bases]
\normalfont  Two arbitrary and distinct bases $\mathbf{B}$ and
$\mathbf{B}^{\prime}$, both in $\mathbb{Z}^{n \times m}$, are
equivalent if and only if there exists a unimodular matrix
$\mathbf{U}\in\mathbb{Z}^{m \times m}$, i.e., $det(\mathbf{U})= \pm
1$ such that $\mathbf{B}^{\prime} = \mathbf{B} \mathbf{U}$.
\end{definition}

The determinant of $\pazocal{L}(\mathbf{B})$ is given as the volume
of $\pazocal{P}(\mathbf{B})$ for some basis $\mathbf{B}$. For
definition of the same lattice under equivalent bases, volume of
$\pazocal{P}(\mathbf{B})$ remains constant since only the shape of
the half-open parallelepiped changes under inter-conversion between
equivalent bases, further implying that determinant is invariant
under change of bases. Geometrically, the determinant is the inverse
of density of lattice points.

\begin{definition}[Norm]
\normalfont  Given a finite n-dimensional vector $\mathbf{x}$, the
$l_{p}$ norm of $\mathbf{x}$ for $p \, \geq \, 1$ is given as
$\parallel \mathbf{x} \parallel _{p} \, = \, (x_{1}^{p} \, + \,
x_{2}^{p} \, + \, \cdots \, + \, x_{n}^{p})^{1/p}$, where
$\mathbf{x} \, = \, (x_{1}, \, x_{2}, \, \cdots, \, x_{n})$.
\end{definition}

 The value of $p$ can be infinite. $l_{\infty}$ is then defined as the \textit{max-norm}: $\parallel \mathbf{x} \parallel _{\infty} \, = \, \mbox{\textbf{Max}}\{x_{1}, \, x_{2}, ..., \, x_{n} \}$.

\begin{definition}[Open ball]
\normalfont  An $n$-dimensional open ball of radius $r$ centered in
$\mathbf{x}$ is defined as $\mathcal{B}(\mathbf{x},r)$ $=$
$\{\mathbf{y}\in\mathbb{R}^{n}:$$\parallel$$\mathbf{x}-\mathbf{y}\parallel$$<r\}$.
\end{definition}

\begin{definition}[Successive minima]
\normalfont  Successive minima for a lattice
$\pazocal{L}(\mathbf{B})$, definable for any norm $p \, \geq \, 1$
and arbitrary basis $\mathbf{B} \, \in \, \mathbb{Z}^{n \times m}$,
are given as $\lambda_{i}(\mathbf{B}) \, = \mbox{\textbf{Min}}\{r:
dim(\pazocal{L}(\mathbf{B}) \, \cap \, \mathcal{B}(\mathbf{x},r)) \,
\geq \, i \}$.
\end{definition}
%, where $\mathcal{B}(\mathbf{x},r))$ represents a $n$-dimensional
%ball of radius $r$ centered around $\mathbf{x}$

Informally, the value of $i$-th successive minimum represents the
minimum length $r$ such that a ball of radius $r$ centered about a
point $\mathbf{x}$ contains at least $i$ independent vectors.
Several upper bounds on $\lambda_{i}(\mathbf{B})$ can be expressed
in the form of the determinant of the lattice, formally known as
Minkowski's theorem.

\begin{theorem}[Minkowski's theorem]
\normalfont For any lattice $\pazocal{L}(\mathbf{B})$,
$$ \{ \, \, \, \prod_{i=1}^{n} \lambda_{i}(\pazocal{L}(\mathbf{B})) \, \, \,   \}^{1/n} \, \leq \, \sqrt{\gamma} \,  det(\pazocal{L}(\mathbf{B}))^{\frac{1}{n}}$$

where the approximation factor $\gamma \, \leq \, n$ is a function of the dimension only.
\end{theorem}

\subsection{$q$-ary lattices}
Given an integer $q$ and a basis $\mathbf{B} \, \in \, \mathbb{Z}^{n
\times m}$, the \textit{q-}ary lattice is an integer lattice
$\pazocal{L}(\mathbf{B})$ such that $\mathbb{Z}^{n}_{q}\, \subseteq
\, \pazocal{L}(\mathbf{B}) \, \subseteq \, \mathbb{Z}^{n}$. Any
integer lattice is \textit{q}-ary for some $q$. There exists a
one-to-one correspondence between \textit{q}-ary lattices of
dimension $n$ and subgroups of $\mathbb{Z}^{n}_{q}$. Inclusion on
any vector $\mathbf{x} \, \in \, \mathbb{Z}^{n}$ in a \textit{q}-ary
lattice depends only upon $\mathbf{x} \, \, \, mod \, \, q$.
\begin{definition}
\normalfont Let $\mathbf{A}\in\mathbb{Z}_{q}^{n\times m}$ be an
integral matrix with modulo $q$, then the following \textit{q-ary}
lattices are defined:
\begin{itemize}
\item[]$\Lambda_{q}^{\perp} = \{\mathbf{t}\in\mathbb{Z}^{n}:\mathbf{A}\mathbf{t} = \mathbf{0}~\mbox{mod}~q\}$
\item[]$\Lambda_{q} = \{\mathbf{t}\in\mathbb{Z}^{n}~\mbox{and}~\mathbf{u}\in\mathbb{Z}^{m}:\mathbf{t} = \mathbf{A^T}\mathbf{u}~\mbox{mod}~q\}$
\end{itemize}
\end{definition}


\subsection{Dual lattice}
\begin{definition}[Dual lattice]
\normalfont  Given a basis $\mathbf{B} \, \in \, \mathbb{Z}^{n
\times m}$ and the consequent lattice $\pazocal{L}(\mathbf{B})$, the
dual lattice to $\pazocal{L}(\mathbf{B})$ is defined as
$\pazocal{L}^{*}(\mathbf{B}^{*}) \, = \, \{\mathbf{x}: \, \langle
\mathbf{x}, \, \mathbf{y} \rangle \in \mathbb{Z}, \forall \mathbf{y}
\, \in \pazocal{L}(\mathbf{B}) \}$.
\end{definition}

\begin{lemma}
\normalfont  The dual of a lattice $\pazocal{L}(\mathbf{B})$ is a
lattice $\pazocal{L}(\mathbf{B}^{*})$ with the basis
$\mathbf{B}^{*}$, where $\mathbf{B}^{*} \, = \,
\mathbf{B}(\mathbf{B}^{T} \mathbf{B})^{-1}$.
\end{lemma}


\subsection{Cyclic and ideal lattices}

\begin{definition}[Rotation shift operation]
\normalfont  For an arbitrary vector $\mathbf{x} \, \in \,
\mathbb{R}^{n}$, the rotation shift operator, represented as
$\mbox{\textbf{Rot}}(\mathbf{x}$), is defined as
$\mbox{\textbf{Rot}}(\mathbf{x}) = x_{n}, \, x_{1}, \, x_{2}, \,
\cdots, x_{n-1}$, where $\mathbf{x} = (x_{1}, \, x_{2}, \, \cdots,
\, x_{n})$.
\end{definition}

Repeated application of the operation can be represented as a raised
whole number index on $\mbox{\textbf{Rot}}$ such as
$\mbox{\textbf{Rot}}^{0}(\mathbf{x})$,
$\mbox{\textbf{Rot}}^{1}(\mathbf{x})$, or
$\mbox{\textbf{Rot}}^{k}(\mathbf{x})$.

\begin{definition}[Cyclic lattice]
\normalfont  For a given basis $\mathbf{B} \, \in \, \mathbb{Z}^{n
\times m}$, the lattice $\pazocal{L}(\mathbf{B})$ is said to be
cyclic if and only if, for any positive integer $k$,
$\mbox{\textbf{Rot}}^{k}(x) \, \in \, \pazocal{L}(\mathbf{B})$.
\end{definition}

For the usual definitions of rings, isomorphism, and polynomials,
ideal lattices are lattices corresponding to ideals in quotient
polynomial rings $\mathbb{Z}[x]/ \langle f(x) \rangle$ for some
irreducible \textbf{monic} polynomial $f(x)\,\in\,\mathbb{Z}[x]$. A
polynomial $f(x)$ is called a \emph{\textbf{monic polynomial}} if
the leading coefficient of $f(x)$ is 1.

\begin{definition}[Ideal lattice]
\normalfont  Given an arbitrary basis $\mathbf{B} \, \in \,
\mathbb{Z}^{n \times m}$, an ideal lattice is an integer lattice
$\pazocal{L}(\mathbf{B}) \, \subseteq \,\mathbb{Z}^{n}$ such that
$\pazocal{L}(\mathbf{B})\, = \,
\{g(x)~\mbox{mod}~f(x):\,g(x)\,\in\,I(x)\}$ for
$I(x)\,\in\,\mathbb{Z}[x]/\langle f(x)\rangle$ for some
\textit{\textbf{monic}} polynomial $f(x)$ of degree $n$.
\end{definition}

There exists an isomorphism between the integer lattice
$\mathbb{Z}^{n}$ and $\mathbb{Z}[x]/\langle f(x)\rangle$.
Multivariate extension is given as $\mathbb{Z}[x_{1}, x_{2}, \cdots,
x_{n}]/\langle x_{1}^{r_{1}} - 1, x_{2}^{r_{2}} - 1, \cdots,
x_{n}^{r_{n}} - 1,  \rangle$ such that $r_{1} \times r_{2} \times
r_{3} \times\cdots\times r_{k} = n$.


\subsection{Computational Problems}
Computational problems can be defined in three equivalent versions:
search version, optimization version, and the decision version.
Search version requires to \textit{search} for the solution amongst
a set of possible solutions, the optimization version requires to
search for a solution that optimizes a certain criterion, while the
decision version requires outputting a binary decision on whether a
specified property is met or not.

For the usual meaning of complexity classes $P$ and $NP$ ($NP$-hard
and $NP$-complete), a reduction from a problem $A$ to another
problem $B$ implies converting any instance of $A$ to some instance
of $B$. This means given access to an oracle of $B$, $A$ can be
solved; it is thus stated that $A$ is not harder than $B$. In all
the succeeding sections, the notion of polynomial-time reductions is
used: for any two decision problems $A$ and $B$, $A$ is said to be
reducible to $B$ if and only if there exists a polynomial-time
bounded function $f$ such that $x \, \in \, A$ if and only if $f(x)
\, \in \, B$ (in this explanation, a decisional problem is  defined
as determining whether an arbitrary input $x$ belongs to the
language represented by the problem $A$, where the reader is
referred to the concepts of \textit{language} as used in the theory
of computation).

All definitions henceforth are the approximate versions of the
corresponding problems. Exact versions are derivable by fixing the
approximation factor $\gamma \, = \, 1$.

\begin{definition}[Minimum distance]
 \normalfont The \textbf{minimum distance} of a lattice $\pazocal{L}(\mathbf{B})$ can be expressed as:
\begin{equation*}
 d_{min}(\pazocal{L})=\underset{\mathbf{v}\in\pazocal{L}\backslash \{\mathbf{0}\}}{\mbox{\textbf{Min}}}\parallel
\mathbf{v}\parallel
\end{equation*}
\end{definition}


\begin{definition}[Shortest vector problem (SVP)]
\normalfont Let $\mathbf{B}\in\mathbb{Z}^{n\times m}$ be a basis
matrix of the lattice $\pazocal{L}(\mathbf{B})$, finding a non-zero
vector $\mathbf{v}\in\pazocal{L}(\mathbf{B})$ such that $\parallel
\mathbf{v}\parallel = d_{min}(\pazocal{L})$ is hard.
\end{definition}

\begin{definition}[Closest vector problem (CVP)]
\normalfont Let $\mathbf{B}\in\mathbb{Z}^{n\times m}$ be a basis
matrix of the lattice $\pazocal{L}(\mathbf{B})$ and $\mathbf{v}$ be
a vector such that $\mathbf{u}\notin\pazocal{L}$, finding a non-zero
vector $\mathbf{v}\in\pazocal{L}$ such that
$\parallel\mathbf{u}-\mathbf{v}\parallel = d_{min}(\pazocal{L})$ is
hard.
\end{definition}



\begin{definition}[Approximate SVP]
\normalfont  Given a basis $\mathbf{B}\in\mathbb{Z}^{n\times m}$ of
a lattice $\pazocal{L}(\mathbf{B})$, and an approximation factor
$\gamma\geq1$ as function of the dimension $n$ of
$\pazocal{L}(\mathbf{B})$, approximate versions of SVP are given as:
\begin{itemize}
\item~\textbf{Search SVP$_{\gamma}$:}~Find a non-zero vector $\mathbf{v}\in\pazocal{L}(\mathbf{B})$ such that $\parallel \mathbf{v} \parallel _{2} \, \leq \, \gamma\cdot\lambda_{1}(\pazocal{L}(\mathbf{B}))$

\item~\textbf{Optimization SVP$_{\gamma}$ (OptSVP$_{\gamma}$):}~Find $d$ such that $d\leq\lambda_{1}\cdot(\pazocal{L}(\mathbf{B}))<\gamma\cdot$$d$.

\item~\textbf{Decisional SVP$_{\gamma}$ (GapSVP$_{\gamma}$):}~Given a positive rational number $r$, determine whether $\lambda_{1}\cdot(\pazocal{L}(\mathbf{B}))\leq$$r$ or $\lambda_{1}(\pazocal{L}(\mathbf{B}))> \gamma\cdot$$r$
\end{itemize}
\end{definition}

\begin{definition}[Approximate CVP]
\normalfont Given a lattice basis $\mathbf{B}\in\mathbb{Z}^{n\times
m}$, a target vector $\mathbf{t}\in\mathbb{R}^{n}$, and an
approximation factor $\gamma$ as function of the dimension $n$ of
$\pazocal{L}(\mathbf{B})$, approximate versions of CVP are given as:

\begin{itemize}
\item~\textbf{Search CVP$_{\gamma}$:}~Find a vector $\mathbf{v}\in\pazocal{L}(\mathbf{B})$ such that $\parallel \mathbf{t} - \mathbf{v}\parallel_{2}\leq\gamma\cdot$$\mbox{\textbf{dist}}(\mathbf{t}, \pazocal{L}(\mathbf{B}))$, where $\mbox{\textbf{dist}}(\mathbf{t}$, $\pazocal{L}(\mathbf{B}))$ is the distance of $\mathbf{t}$ from $\pazocal{L}(\mathbf{B})$.

\item~\textbf{Optimization CVP$_{\gamma}$ (OptCVP$_{\gamma}$):}~Find $d$ such that $d\leq\mbox{\textbf{dist}}(\mathbf{t}$, $\pazocal{L}(\mathbf{B}))<\gamma\cdot$$d$.

\item~\textbf{Decisional CVP$_{\gamma}$ (GapCVP$_{\gamma}$):}~Given a positive rational number $r$, distinguish between $\mbox{\textbf{dist}}(\mathbf{t}, \pazocal{L}(\mathbf{B}))\leq r$ and $\mbox{\textbf{dist}}(\mathbf{t}, \pazocal{L}(\mathbf{B}))>\gamma\cdot$$r$.
\end{itemize}
\end{definition}

\begin{definition}[Shortest independent vectors problem (SIVP)]
 \normalfont Given a basis matrix $\mathbf{B}=[\mathbf{b_{1}}$,
 $\mathbf{b_{2}}$, $\mathbf{b_{3}}$, $\cdots$, $\mathbf{b_{m}}]$
 of the lattice $\pazocal{L}(\mathbf{B})$ of dimension $n$, find $n$
 linearly independent vectors $\mathbf{v}_{1}$, $\mathbf{v}_{2}$,
 $\cdots$, $\mathbf{v}_{n}$ such that $\mbox{\textbf{Max}}\|\mathbf{v}_{i}\|\leq\mbox{\textbf{Max}}_{\mathbf{B}}\|\mathbf{b}_{i}\|$.
\end{definition}


\begin{definition}[Approximate SIVP]
\normalfont Given a lattice basis $\mathbf{B}\in\mathbb{Z}^{n\times
m}$, and an approximation factor $\gamma$ as function of the
dimension $n$ of $\pazocal{L}(\mathbf{B})$,
 approximate versions of SIVP are given as:
\begin{itemize}
\item~\textbf{Search SIVP$_{\gamma}$ (SIVP$_{\gamma}$):}~Find $n$ linearly independent vectors
$\mathbf{v}_{1}, \mathbf{v}_{2}, \cdots, \mathbf{v}_{n}\in
\pazocal{L}(\mathbf{B})$ of length $\mbox{\textbf{Max}}\parallel
\mathbf{v}_{i}\parallel_{2}\leq\gamma\cdot\lambda_{n}(\pazocal{L}(\mathbf{B}))$.

\item~\textbf{Optimization SIVP$_{\gamma}$ (OptSIVP$_{\gamma}$):}~Find $d$ such that $d\leq\lambda_{n}\cdot(\pazocal{L}(\mathbf{B}))<\gamma\cdot$$d$.
%Compute $\lambda _{n}(\pazocal{L}(\mathbf{B}))$ up to a factor of $\gamma$

\item~\textbf{Decisional SIVP$_{\gamma}$ (GapSIVP$_{\gamma}$):}~Given additionally a positive rational number $r$, distinguish between $\lambda_{n}(\pazocal{L}(\mathbf{B}))\leq r$ or
$\lambda_{n}(\pazocal{L}(\mathbf{B}))>\gamma\cdot$$r$.
\end{itemize}
\end{definition}

\begin{definition}[Covering radius]
\normalfont The covering radius in the $l_{p}$ norm of a full-rank
lattice $\pazocal{L}(\mathbf{B})\in\mathbb{R}^{n}$ is defined as
$$\rho(\pazocal{L}(\mathbf{B})) =
\mbox{\textbf{Max}}_{\mathbf{x}\in\mathbb{R}^{n}}\textbf{\mbox{dist}}(\mathbf{x},
\pazocal{L}(\mathbf{B}))$$
\end{definition}
The covering radius $\rho$ of $\pazocal{L}(\mathbf{B})$ is defined
as the minimum radius of the (closed) spheres when centered at all
lattice points cover the entire space, i.e., any point in
\textbf{span}($\mathbf{B}$) is within distance $\rho$ from
$\pazocal{L}(\mathbf{B})$. Note that \textbf{span}($\mathbf{B}$) for
any $\mathbf{B}\in\mathbb{Z}^{n \times m}$ is the set of points
$\{\mathbf{B}\mathbf{x}: \, \mathbf{x}\in\mathbb{R}^{m}\}$.
\textbf{span}($\mathbf{B}$) covers the entire $\mathbb{R}^{n}$
space, with $n$ being the dimensionality of $\mathbf{B}$ if $n = m$.


\begin{definition}[Approximate covering radius problem]
\normalfont\label{crpg}~Given a lattice basis $\mathbf{B}$, and an
approximation factor $\gamma$ as function of the dimension $n$ of
$\pazocal{L}(\mathbf{B})$, approximate versions of CRP are given as:

\begin{itemize}
\item~\textbf{Search CRP$_{\gamma}$):}~No known problem formulation whose solution is verifiable in polynomial time
\cite{CRHF_Goldwasser}.

\item~\textbf{Decisional CRP$_{\gamma}$ (GapCRP$_{\gamma}$):}~Given additionally a positive rational number $r$,
distinguish between $\rho (\pazocal{L}(\mathbf{B}))\leq$$r$ and
$\rho(\pazocal{L}(\mathbf{B}))>\gamma\cdot$$r$ where $\rho$ is the
covering radius.
\end{itemize}
\end{definition}

\begin{definition}[Approximate unique shortest vector problem (u-SVP)]
\normalfont Given a basis matrix $\mathbf{B}$ of
$\pazocal{L}(\mathbf{B})$, the promise that
$\lambda_{2}(\mathbf{B})>\gamma\cdot\lambda_{1}(\mathbf{B})$, and an
approximation factor $\gamma$ as function of the dimension $n$ of
$\pazocal{L}(\mathbf{B})$, approximate search version of u-SVP is
given as:
\begin{itemize}
\item \textbf{Search u-SVP$_{\gamma}$:}~Find a non-zero vector
$\mathbf{v}\in\pazocal{L}(\mathbf{B})$ such that $\parallel
\mathbf{v}\parallel_{2}\leq\gamma\cdot\lambda _{1}(\mathbf{B})$
\end{itemize}
\end{definition}

\begin{definition}[Approximate guaranteed distance decoding problem (GDD)]
\normalfont Given a basis matrix $\mathbf{B}$ of
$\pazocal{L}(\mathbf{B})$, a target vector
$\mathbf{t}\in\mbox{\textbf{span}}(\mathbf{B})$, and an
approximation factor $\gamma$ as function of the dimension $n$ of
$\pazocal{L}(\mathbf{B})$, approximate search version of GDD is
given as:
\begin{itemize}
\item\textbf{Search GDD$_{\gamma}$:}~Find a vector $\mathbf{v} \, \in \,
\pazocal{L}(\mathbf{B})$ such that \textbf{dist}($\mathbf{t}$,
$\mathbf{v}$) $\leq \, \gamma\cdot\rho(\pazocal{L}(\mathbf{B}))$,
where $\rho$ is the covering radius of$\pazocal{L}(\mathbf{B})$.
\end{itemize}
\end{definition}

In these and other similar lattice problems, the approximate factor
$\gamma$ is considered a function of the dimension of the lattice.
Several years of research has strengthened the conjecture that
achieving polynomial approximation factors $\gamma$ from polynomial
time algorithms is intractable, allowing these problems to be the
basis of security of various lattice based cryptographic primitives.

\begin{definition}[Negligible function]
\normalfont A function $\epsilon (k):\mathbb{N} \rightarrow
\mathbb{R}$ is said to be negligible if, for every integer $v>0$,
there exists an integer $u$ such that $\epsilon
(k)\leq\frac{1}{k^{v}}$ holds $\forall \, k\geq u$
\end{definition}

\section{Discussion on collision-free hash function}
Theoretically, cryptographic schemes are never secure in the face of
an adversary with unbounded computational capacity. Practically,
however, all adversaries are limited by the computational capacity
they have. A cryptographic scheme is considered secure if an
adversary can not, with non-negligible probability, break it
efficiently. To formally quantify \textit{non-negligible}
probability, negligible functions are considered.

\begin{definition}[Collision-free hash function]
\normalfont A Collision resistant hash function $h(\cdot)$ is
defined as a keyed function $h:\{0,1\}^{a}\rightarrow \{0,1\}^{b}$
if it satisfies the following two properties:
\begin{enumerate}[label=\textbf{(\arabic*).}]
\item~\textbf{Compression:}~$a>b$

\item~\textbf{Collision resistance:}~there exists a negligible function $\epsilon(n)$ for all security parameters $n\in\mathbb{N}$ such that:

$$\textbf{\mbox{Pr}}[x, y \leftarrow_{R}\{0,1\}^{a}:~x\neq y~\mbox{and}~h(x) = h(y)]\leq\epsilon(n)$$ where $x\leftarrow_{R}\{0,1\}^{a}$ represents a sample $x$ is drawn at random from $\{0,1\}^{a}$ with uniform probability distribution.
\end{enumerate}
\end{definition}
Or, the conditional probability of finding distinct $x$ and $y$ from
$\{0,1\}^{a}$ such that $h(x) = h(y)$ is negligible. More
concretely, collision resistance property is required on a family
$\pazocal{H}$ of hash functions, so that a non-uniform adversary
$\pazocal{A}$ can not efficiently find collisions for a Collision
resistant hash function $h(\cdot)$ drawn at random from
$\pazocal{H}$.

\subsection{Collision-free hash function proposed by Goldreich et al. \cite{CRHF_Goldreich1996}}
The first breakthrough in constructing lattice-based primitives was
Ajtai's seminal works \cite{CRHF_Ajtai1996,CRHF_BBD} in which was
presented a family of one-way functions based on the worst-case
hardness of $n^{c}$-approximate SVP for some constant $c>0$. Being
able to invert a function from this family with non-negligible
probability means solving \textit{any} instance (since the
assumption was worst-case hardness) of the $n^{c}$-approximate SVP
problem. Goldreich \textit{et. al.} \cite{CRHF_Goldreich1996}
modifies Ajtai's work \cite{CRHF_Ajtai1996} to construct a
collision-free hash function family on nearly the same lines as
Ajtai did. The main result is the construction of two similar hash
function families based on modular linear equations. Of independent
interest to the reader is the mathematics for the procedure to
establish worst-case to average-case reductions: a sampling
procedure wherein a large space is considered and is divided into
sub-regions ensuring \textit{almost} uniform distribution of lattice
points, such that sampling from such sub-regions yields useful
\textit{short} vectors while being \textit{almost} uniformly
distributed over the concerned group, usually $\mathbb{Z}_{q}^{n}$.

For a given security parameter $n$, a matrix
$\mathbf{A}\in\mathbb{Z}_{q}^{n\times m}$ is chosen uniformly at
random, $m$ and $n$ are chosen such that $n\,\mbox{log}q<
m<\frac{q}{2n^{4}}$, $q=\pazocal{O}(n^{c})$ (i.e.,
$m=\pazocal{O}(n^{2})$, $q=\pazocal{O}(n^{7})$) for some constant
$c>0$. The hash function family $h_{\mathbf{A}}:\{0,
1\}^{m}\leftarrow\mathbb{Z}_{q}^{n}$ is defined for a binary message
$\mathbf{x}$ $=$ $\{\mathbf{x}_{1}$, $\mathbf{x}_{1}$, $\cdots$,
$\mathbf{x}_{m}\}\in\{0, 1\}^{m}$ as

$$h_{\mathbf{A}}(\mathbf{x})=\mathbf{A}\mathbf{x}~(\mbox{mod}~q)$$

Since $m>n\,\mbox{log}q$, therefore collisions are necessarily
existent in $h_{\mathbf{A}}$. The main difference from Ajtai's
initial construction is the constraint on the input domain to the
hash function to be a binary vector. To find collisions for distinct
lattice vectors say $\mathbf{a}$ and $\mathbf{b}$ such that
$\mathbf{x}\,=\,\mathbf{a} \, - \, \mathbf{b}$, Ajtai considered
$\{\mathbf{x}\,\in\,\mathbb{Z}_{q}^{m}:\,\parallel \mathbf{x}
\parallel_{2}\,<\,n \,;\,\mathbf{A}\mathbf{x}\,\equiv 0(\mbox{mod}~q)\}$.
However, Goldreich \textit{et. al.} \cite{CRHF_Goldreich1996}
consider $\mathbf{x}$ to be strictly a binary vector, a harder
constraint on the length of the vector, which is now
$\pazocal{O}(\sqrt{m})$.

Goldreich \textit{et. al.} \cite{CRHF_Goldreich1996} also define
family as
$h_{\mathbf{A},\mathbf{r}}(\mathbf{x})\,=\,\mathbf{A}\mathbf{x}\,+\,\mathbf{r}$
for an additional random vector
$\mathbf{r}\,\in\,\mathbb{Z}_{q}^{n}$. This ensures the construction
to be \textit{universal} or any two images are spread uniformly over
the range in a pairwise independent manner. Both these families are
collision resistant due to the constraint on the input vector, as
discussed above.

\noindent\textbf{Remark:}~The constant $c$ in Ajtai's work
\cite{CRHF_Ajtai1996} and Goldreich \textit{et. al.}
\cite{CRHF_Goldreich1996} was tightened further by Cai \textit{et.
al.} \cite{CRHF_Cai1997}, \cite{CRHF_Cai1999} reducing $c\,>\,8$ in
the former works to $c\,=\,4+\epsilon$ in the latter. Further
tightening of the bound was done by Micciancio
\cite{CRHF_Micciancio2002} where hardness of one-way and collision
resistant functions respectively was still based on
$n^{c}$-approximate SVP with reductions in the approximation factor
further to $\pazocal{O}(\tau n^{3}\,log\,n)$ with $\tau \,\in\,
[1,\sqrt{n}]$ or roughly to a factor of $3+\epsilon$ ($\tau$ is the
ratio of covering radius of the lattice to the packing radius of the
lattice, for usual definitions of covering and packing radii for
lattices). This improvement is based on \emph{covering radius
problem} (Definition~\ref{crpg}) on lattices, and the reductions
that follow therein. \textcolor{red}{No deterministic algorithm is
known that can solve CRP in \textit{polynomial time}, thereby
implying CRP is probably harder than SVP or other well-studied
lattice-based problems. A construction based on CRP can thus be
considered secure based on assumed hardness of CRP.}

Let the output of a hash function $h_{\mathbf{A}}(\mathbf{x})$ be in
$\mathbb{Z}_{q}^{n}$, for some appropriate integer $q$. This is a
finite, abelian group that can be considered equivalent as the
quotient group $\mathbb{Z}^{n}/q\mathbb{Z}^{n}$. $q\mathbb{Z}^{n}$
is naturally partitioned into $q^{n}$ hyper-cubes, with each
hyper-cube corresponding to some element in
$\mathbb{Z}^{n}/q\mathbb{Z}^{n}$, and thus to some element in
$\mathbb{Z}_{q}^{n}$. Consider another lattice
$\pazocal{L}(\mathbf{B})$ generated by basis $\mathbf{B}$ and let
each partitioned hyper-cube of $q\mathbb{Z}^{n}$ contain roughly the
same number of lattice points in $\pazocal{L}(\mathbf{B})$. We want
to estimate number of such points in each hyper-cube, and connect
hardness of doing so with the security of the described hash
functions. However, the main improvement in approximation factor in
this work, as discussed earlier, comes from replacing such
hyper-cubes with another construction called Voronoi cells. For
lattices considered in this work, Voronoi cells are \textit{almost}
spherical, thereby saving up on space occupied with cubes (precisely
hyper-cubes) and causing an efficient partition of space.

\begin{definition}[Voronoi cell]
\normalfont Voronoi cell for a certain lattice point
$\mathbf{x}\,\in\, \pazocal{L}(\mathbf{B})$ is described as
$V(\mathbf{x},
\pazocal{L})\,=\,\{\mathbf{z}\in\mbox{\textbf{span}}(\pazocal{L}):\forall
\mathbf{y}\,\in\,\pazocal{L}(\mathbf{B}),\,\parallel \mathbf{z} -
\mathbf{x}\parallel_{2} \,\leq\,\parallel \mathbf{z} - \mathbf{y}
\parallel_{2} \}$, i.e., the set of points that are closer
to $\mathbf{x}$ than to any other point in
$\pazocal{L}(\mathbf{B})$. The main property of Voronoi cells:

$$\mbox{sphere~of~radius}~\frac{\lambda_{1}}{2}\subset V(\mathbf{x},\pazocal{L})\subset\mbox{sphere~of~radius}~\rho$$

where $\rho$ and $\frac{\lambda_{1}}{2}$ are the is the covering
radius and packing radius of of $\pazocal{L}(\mathbf{B})$,
respectively, \textcolor{red}{for the usual definition of
$\lambda_{1}$ in the definition of the \textit{approximate}-SVP}.
When $\tau$ is balanced, the packing and covering radii are almost
equal implying $V(\mathbf{x},\pazocal{L})$ are \textit{almost}
spherical. The idea about Voronoi cells is essential for detailed
proofs, for which we refer the reader to the original work.
\end{definition}

\subsection{Generalized hash function proposed by Goldreich et al. \cite{CRHF_Goldreich1996}}
For an arbitrary lattice $\mathbf{A}$ and a scaling factor $\alpha$,
a sub-lattice $\pazocal{L}(\mathbf{M})\, \subset \, \mathbf{A}$ is
defined as $\mathbf{M} \, = \, \alpha \rho(\mathbf{A})\textbf{I} +
\textbf{R}$, where $\mathbf{I}$ is the identity matrix while
$\mathbf{R}$ is a matrix chosen at random such that the lengths of
columns of $\textbf{R}$ are upper-bounded by $\rho(\mathbf{A})$, or
informally lattice points in $\pazocal{L}(\mathbf{M})$ that are
within a distance of $\rho(\mathbf{A})$ of lattice points in
$\mathbf{A}$. Define a finite abelian group $G \, = \,
\mathbf{A}/\pazocal{L}(\mathbf{M})$. Representation of $G$ is
possible such that elements of $G$ can be represented as
$\mbox{log}_{2}\mid G\mid$ bits. The hash function is then given as
$h_{\mathbf{a}}:\, \{0,\,1\}^{m} \, \rightarrow \, G$ for input
binary string $\mathbf{x}$ of length $m$.

$$h_{\mathbf{a}}(\mathbf{x}) \, = \, \sum_{i=1}^{m}a_{i}x_{i}$$

for some key $\mathbf{a} \, \in \, G^{m}$. Evidently, collisions
exist for $m >\mbox{log}_{2}\mid G\mid$. Also note the following
relation holds $\mbox{log}_{2}\mid G\mid<n(\mbox{log}_{2}n+
\mbox{log}_{2}\alpha)$. For parameter $\alpha$ chosen to be
asymptotically similar to $n$, this expression reduces to
$\pazocal{O}(n\mbox{log}_{2}n)$ and gives an upper bound on the
output domain of the hash function. Finally, finding collisions for
any $\mathbf{a}$ chosen uniformly at random from $G^{m}$ is at least
as hard as approximating covering radius for any lattice up to
factors of $\gamma$, thereby establishing security of the hash
function.

\noindent\textbf{Remark:}~ Micciancio and Regev
\cite{CRHF_Micciancio2004} further reduced the approximation factor
to linear in \textit{n} using Gaussian measures, and improved on the
assumptions in \cite{CRHF_Regev} where the hardness is based on
approximate \textit{unique}-SVP that is not known to be NP-hard for
small approximation factors. This work is important in a number of
respects: connecting hardness of defined hash function family with
worst case hardness of SVP, SIVP, and CRP for approximation factors
up to $\Tilde{\pazocal{O}}(n)$, introduce a general abstraction of
procedure for worst-case to average-case reduction that might be of
independent interest to the reader, and introduce techniques based
on Gaussian measures that help in reductions among lattice problems,
again of probable independent interest to the reader.

In brief, the authors \cite{CRHF_Micciancio2004} designed a hash
function family on SIS problem. Given a hash function
$h_{\mathbf{a}}$ taken uniformly at random from the hash function
family such that $$h_{\mathbf{a}}(\mathbf{x})\, =\, \mathbf{A}
\mathbf{x}~\mbox{mod}~q$$ for $\mathbf{A} \, \in \,
\mathbb{Z}_{q}^{n \times m}$, $\mathbf{x}\,\in\,\{ 0,\,1\}^{m}$, $q
\, = \, n^{\pazocal{O}(1)}$ and $m \, > \, n\mbox{log}_{2}q$ for
collisions to necessarily exist. For distinct input vectors
$\mathbf{a}$ and $\mathbf{b}$, existence of collision implies
$\mathbf{A} \mathbf{a} \, - \, \mathbf{A}
\mathbf{b}\equiv\mathbf{0}~\mbox{mod}~q$ i.e., $\mathbf{A}
\mathbf{z}\equiv\mathbf{0}~(\mbox{mod}~q)$ such that
$\mathbf{z}\neq\mathbf{0}$. Given the input domain to be $\{0,
1\}^{m}$, it is easy to see that $\parallel\mathbf{z}
\parallel_{\infty} \, = \, 1$. The problem of finding collisions is thus reduced to
finding short integer solutions to this homogeneous equation, which
is intractable in polynomial time. The requirement in the entire
setup is that $\mathbf{A}$ must be chosen uniformly at random from
$\mathbb{Z}_{q}^{n \times m}$. This work is also interesting for a
general take on approaches to worst-case to average-case reductions
(for true average-case instantiations of the hash functions). Almost
all the previous works \cite{CRHF_Ajtai1996},
\cite{CRHF_Goldreich1996}, \cite{CRHF_Cai1997}, \cite{CRHF_Regev},
\cite{CRHF_Micciancio_perfect_lattices} follow a similar approach
that is abstracted here. Note that outputs of the hash function are
usually in $\mathbb{Z}_{q}^{n}$. The basic idea is to search for the
existence of a polynomial-time sampling procedure that samples group
elements and corresponding \textit{offset} vectors (this offset
vector doesn't need to be in the lattice defined). Should this
offset vector (compare with $\mathbf{z} \, = \, \mathbf{a}\,-\,
\mathbf{b}$) be the solution of the homogeneous modular linear
equation, it implies the offset vector maps to an actual lattice
point. Depending on the norm of the sampled vector (compare with the
norm, especially with $l_{2}$ norm, of $\mathbf{a}$ and
$\mathbf{b}$), the offset vector can be considered short, implying
it maps to a short vector in the lattice.

The difference between works lies in the way the sampling procedure
works. This work details a method of division of a large hypercube
into smaller hyper-cubes such that each hypercube corresponds to
some element of $\mathbb{Z}_{q}^{n}$. The sampling procedure is
constructed around this idea, such that for every sample from
$\pazocal{L}(\mathbf{B}) \, \cap\, q\mathbb{Z}^{n}$, there is a
corresponding smaller hypercube $C$ wherein that sample lies and a
corresponding offset vector concerning the center of $C$. The
construction of these smaller hypercubes plays an important part:
smaller hypercubes are small enough that the offset vectors are
small, and large enough that almost equal number of lattice points
in $\pazocal{L}(\mathbf{B})$ lie in each of the smaller hyper-cubes,
thereby ensuring uniformly at random distribution over
$\mathbb{Z}_{q}^{n}$. The reader is also referred to an earlier
section for improved sampling procedure wherein Voronoi cells
instead of smaller hypercubes were considered, and lattice
$\pazocal{L}(\mathbf{B})$ was chosen such that these cells are
almost spherical ensuring tighter packing (and thus even shorter
offset vectors) and better approximation factors and improved
security.

The sampling procedure from this work takes a different path, which
is primarily responsible for efficient approximation factors.
Instead of dividing large space into sub-spaces, the authors take a
random lattice point and a random noise vector with a Gaussian
distribution and reduce the noise vector modulo the basis such that
a uniform distribution is obtained the fundamental parallelepiped.
This fundamental parallelepiped is divided into $q^{n}$ sub-regions
to correspond to group elements in $\mathbb{Z}_{q}^{n}$; the reduced
noise vector then induces almost uniform distribution over
$\mathbb{Z}_{q}^{n}$. Such additions of Gaussian blur to smooth a
discrete lattice into (almost) uniform distribution is also seen in
Regev\cite{CRHF_Regev}, which is described next. The work of
Regev\cite{CRHF_Regev} is based on the assumed hardness of
$n^{c}$-$u$SVP problem (to find the shortest non-zero vector in a
$n$-dimensional lattice with the promise that it is shorter than all
other non-parallel vectors by a factor of $n^{c}$). It introduces
the idea of Fourier analysis as an integral part of lattice-based
constructions. Earlier indirect applications of Fourier analysis was
through transference theorems in the works of Cai \textit{et.
al.}\cite{CRHF_Cai1999}.

The hash function family considered is the modular subset sum
function (whose security is based on the worst case hardness of
$\pazocal{O}(n^{1.5})$-$u$SVP), also appearing independently in
Impagliazzo \textit{et. al.}\cite{CRHF_Impagliazzo1996} involving an
average-case to average-case reduction of the function. Modular
subset sum problem is a specialized version of the subset sum
problem but with the added constraint that the subset sum is modulo
some positive integer. It was noted by Ajtai\cite{CRHF_Ajtai1996}
that results of hash functions based on random lattices can be
extended to modular subset sum functions, thus connecting author's
present work with past constructions of hash functions. Ajtai's work
\cite{CRHF_Ajtai1996} requires four reductions from instances of the
aforementioned $\pazocal{O}(n^{1.5})$-$u$SVP lattice problem to the
problem of distinguishing between two distributions (a uniform
distribution and a special distribution concentrated around integral
multiples of $\frac{1}{h}$ for some large \textit{unknown} $h$,
where $h$ is functionally related to the shortest vector in the
lattice). The main reduction involves four reductions and contains
ideas about making the lattice sparse without losing the shortest
vector; using this sparse nature of the lattice to ensure if there
exists a short vector of length $\frac{1}{n}$ such that all
non-parallel vectors to this short vector are of length at least
$\frac{n^{1.5}}{n}=\sqrt{n}$; the third step uses a prime idea of
Ajtai and Dwork \cite{CRHF_Ajtai1997} (based on a lemma of
Banaszczyk \cite{CRHF_Banaszczyk1993}) that combines a
\textit{random} lattice point in the dual lattice with a Gaussian of
radius $\sqrt{n}$ to produce two $n$-dimensional distributions
(uniform and specialized as discussed in the statement of the
problem in the first sentence of this paragraph); the last reduction
transforms these $n$-dimensional distributions to one-dimensional
distributions and completes the initial distinguishability problem
described. Here, $n$-dimensional distributions are \textit{random}
vectors whose $n$ components are random variables. There is another
property for the \textit{specialized} distribution centered around
integral multiples of $\frac{1}{h}$. An algorithm able to
distinguish between the distributions as mentioned above for a
non-negligible fraction of values of h can distinguish them for all
values of $h$. The authors provide a detailed proof of the hardness
of this \textit{average case} problem.

A general case hash function on the modular subset set problem is
formulated as $$f(\mathbf{b}) = \sum^{m}_{i =
1}b_{i}a_{i}~\mbox{mod}~N$$ where $\mathbf{b}$ denotes the actual
binary vector to be hashed ($b_{i} \in \{0, 1\}$ for $i = 1, 2, 3,
\cdots, m$) and $m = \pazocal{O} (log N)$ and $a_{i}$ for all $i$
denote the components of the key used in the hash function. A
collision finding algorithm needs to search, with non-negligible
probability, a non-zero vector $\mathbf{a}$ such that $\parallel
\mathbf{a} \parallel_{2} \leq \sqrt{m}$ (sufficiently \textit{short}
vector) and $\sum^{m}_{i =
1}a_{i}a_{i}\equiv\mathbf{0}~(\mbox{mod}~N)$. This algorithm then
has a solution to $n^{c}$-$u$SVP.


\subsection{Collision-free hash function on Cyclic and ideal lattices}
Regarding all suggested schemes discussed before, while the
representation of hash function parameters is feasible in present
memory constraints, the size of the key is a major bottleneck: the
key $\mathbf{A} \in\mathbb{Z}_{q}^{n\times m}$ is chosen uniformly
at random. With growing $n$, $m$ also grows. It was soon observed
that by imposing a special structure on the lattice used, efficient
schemes could be designed. One such scheme proceeds by not choosing
the key $\mathbf{A}$ at random as done in \textcolor{red}{Ajtai's
construction \cite{} give citation} and the improvements thereafter,
but with special cyclic structure. The key would be a block matrix
where each block ($\mathbf{A}^{i}\in\mathbb{Z}_{q}^{n\times m}$) is
a \textit{circulant} matrix. So there exist $\frac{m}{n}$ such
blocks. Two improvements are straightforward: reduced storage size
since only the first column need to be stored (rest of the columns
are simply cyclic permutations of the first column), and the running
time of matrix vector product is reduced to asymptotically linear
time (Fast Fourier Transform (FFT) is applicable due to the cyclic
structure). This structure however invalidates the proofs of
security established by various other works \cite{CRHF_Cai1997},
\cite{CRHF_Micciancio2002}, \cite{CRHF_Micciancio2004} since all of
them assume a uniform distribution of key $\mathbf{A}$ over
$\mathbb{Z}_{q}^{n\times m}$. One proof of security was, however,
given by Micciancio \cite{CRHF_Micciancio2002_compact_knapsacks} who
showed the average hardness of inverting hash functions built upon
the circulant property, but only for few classes of lattices that
were invariant under cyclic rotations of coordinates. It turned out
that finding collisions was not difficult
\cite{CRHF_Lyubashevsky2006}, \cite{CRHF_Peikert2006}. In a way, the
existence of collisions for these functions demonstrates the
importance of theoretical security proofs whenever a cryptographic
construction is modified. The problem of describing
collision-resistant hash functions on lattices was tackled by
Lyubashevsky \textit{et. al} \cite{CRHF_Lyubashevsky2006} and
Peikert \textit{et. al.} \cite{CRHF_Peikert2006}. Both works
\cite{CRHF_Lyubashevsky2006, CRHF_Peikert2006} consider
collision-resistant hash function families built on the generalized
knapsack function on ideal lattices; Lyubashevsky \textit{et. al}
\cite{CRHF_Lyubashevsky2006} takes a more generalized approach than
Peikert \cite{CRHF_Peikert2006} in a sense that it considers general
monic polynomials in the definition of the \textit{ideals} instead
of a specific polynomial ($(\alpha^{n} - 1)$ for variable $\alpha$)
taken in the latter. This improves upon the scheme in
\cite{CRHF_Peikert2006} since choices of the polynomial other than
$(\alpha^{n} - 1)$ lead to better hash function families in some
cases.

The work of Lyubashevsky \textit{et. al}
\cite{CRHF_Lyubashevsky2006} is an extension to the detailed work
done on building hash function families around generalized knapsack
functions. The primary security assumption is the lack of
polynomial-time algorithms to attack lattice problems on ideal
lattices, partly motivated by the fact that algorithms attacking
lattice problems have been unable to take advantage of the cyclic
structure of lattices. Generalized knapsack functions have several
attacks detailed in the works of Joux \cite{CRHF_Joux1994}, Shamir
\cite{CRHF_Shamir1984_MH}, Vaudenay \cite{CRHF_Vaudenay2001} but
these attacks are useless against knapsacks based on ideal lattices.
The collision-resistant hash family $\pazocal{H}(\pazocal{R}, D, m)$
from message domain $D^{m}$ to output domain $\pazocal{R}$ is
defined for $\pazocal{R}\, = \, \mathbb{Z}_{p}[\alpha]/ \langle f
\rangle$ where $\alpha$ is the variable, $D = \{ g\,\in\,
\pazocal{R}:\,\parallel g\parallel_{f} \leq d \}$ for some positive
integer $d$ and polynomial modulo norm $\parallel g \parallel_{f}$
\textcolor{red}{\cite{give a citation here}}, and rank $m$ of the
lattice. Conditions for collision-resistance requires $f$ to be
\textit{irreducible} over the polynomial ring and a certain ratio,
called \textit{expansion factor} to be as low as possible.

\textcolor{red}{The authors \cite{give a citation here}} define a
new hard problem: approximate \textit{shortest polynomial problem}
to establish hardness of their hash function family. For the usual
definition of infinite norm of a vector $\mathbf{x}$, the infinite
norm of a set $S$ is given as $\lambda^{\infty}_{1}(S) =
min\,\{\parallel x\parallel_{\infty}:\,x\,\in\,S\}$. Given a monic
polynomial $f$ of degree $n$ and an ideal $I\,\subseteq \,
\mathbb{Z}[\alpha]/\langle f\rangle$, the problem is to find a
non-zero $g\,\in \,I$ such that

$$\parallel g\parallel_{f} \leq \gamma \lambda^{\infty}_{1}(I)$$

for some approximate factor $\gamma$. The authors provide a detailed proof of polynomial time reduction from this problem to finding collisions, thereby establishing security of the hash function.

For a hash function $h\,\in\, \pazocal{H}$ such that $h_{\mathbf{a}}(\mathbf{b})\,=\,\sum_{i=1}^{m}a_{i}b_{i}$ for key $\mathbf{a} \,\in\, \pazocal{R}^{m}$ and input $\mathbf{b} \,\in\,D^{m}$ where $h$ is uniformly sampled from function family $\pazocal{H}$ at random. Collisions are inevitable for $m\,>\,\frac{log\,p}{log\,2d}$ where $d$ is the parameter in the definition of $D$ such that $\mid D^{m}\mid \,=\, (2d + 1)^{nm}$ and $p$ is such that $\mid \pazocal{R}\mid \,=\,p^{n}$ for dimensionality $n$ and rank $m$ ($\mid .\mid$ denotes the cardinality of the given set, in the usual sense of cardinality). The size of the key in the hash function is $\pazocal{O}(n\,log\,n)$ and hashing of the message can be done in $\pazocal{O}(n\,log\,n\,log\,log\,n)$.


The more specific approach of Peikert \textit{et.al.}\cite{CRHF_Peikert2006} extends Micciancio's work and shows there exist collision-resistant hash functions derived from certain instantiations of generalized knapsack function based on the assumed hardness of approximate \textit{shortest vector problem} in cyclic lattices. This work has a stronger \textit{worst-case} assumption than Micciancio's: SVP is hard on cyclic lattices for all sufficiently large \textit{prime} dimension. The authors formulate the proof using a chain of reductions, thereby introducing several interesting generalised problems on the way which are worth looking at in their own regard. The reader is referred to the original article for detailed discussion.

Since integer cyclic lattices are isomorphic to \textit{ideals} in $\mathbb{Z}[\alpha]/(\alpha ^{n} - 1)$ with $\alpha$ being the indeterminate, $(\alpha ^{n} - 1)$ can be represented in terms of product of cyclotomic polynomials. A cyclotomic polynomial $\Phi_{k}(\alpha)$ is a \textit{minimal} polynomial in the \textit{k}th primitive root of unity ($\zeta$),

$$\Phi_{k}(\alpha) = \prod_{j \in [1, k]; gcd(j,k)=1} (\alpha - \zeta^{j})$$

such that these polynomials are irreducible over $\mathbb{Z}[\alpha]$ and $(\alpha ^{n} - 1)$ can be represented as product of such cyclotomic polynomials. For any given vector \textbf{x} belonging to a field $F$, $x(\alpha) \in F[\alpha]$, or a polynomial in $\alpha$ whose coefficients are the components of $x$. Then, the cyclotomic subspace $H_{\Phi}$ is defined as the \textit{linear} subspace under $\mathbb{R}^{n}$:

$$H_{\Phi} = \{ \mathbf{x} \in \mathbb{R}^{n}:\, \Phi(\alpha)\,\, divides\,\, x(\alpha)\,\, over\,\, \mathbb{R}[\alpha] \}$$

where $\Phi(\alpha)$ is the product of $\Phi_{k}(\alpha)$ for some values of \textit{k}. It is not necessary that $\Phi(\alpha)$ = $(\alpha ^{n} - 1)$.

The cyclotomic versions of worst case lattice problems on cyclic lattices are then described: \textit{subSIVP} and \textit{subSVP}. Both of these problems require a $n$ dimensional full-rank ($rank\,=\,dimension$) cyclic lattice basis B, a polynomial $\Phi(\alpha)$ \textit{not} equal to $(\alpha ^{n} - 1)$ but dividing the latter. Given these conditions, \textit{subSIVP} asks a set of vectors $S$ such that $\parallel S\parallel \leq \gamma(n).\zeta(D)$ and \textit{subSVP} asks for a single vector $\mathbf{m}$ such that $\parallel \mathbf{m}  \parallel \leq \gamma(n).\zeta(D)$. Here $D$ is the domain under consideration (might be the entire lattice or the space defined by $H_{\Phi}$) and $\zeta$ is an arbitrary function ($n$th successive minimum or any other function defined on lattices). The authors note there exist worst-case to worst-case reductions among these versions of computational problems.

The authors base their hash functions on generalised knapsack function defined as $f_{\mathbf{a}}(\mathbf{x}) = \sum_{i = 1}^{m} a_{i}x_{i}$ for some $a_{i} \in \pazocal{R}$ where $\pazocal{R}$ is some ring, and $\mathbf{x} \in S \subseteq R$. The security parameter for the function is the \textit{dimension} of $\pazocal{R}$: $n$ as $\pazocal{R} = (\mathbb{Z}^{n}_{p}, +, \times)$, where $p$ is the positive integer modulo to which integers are present in the $n$ dimensional ring. $S$ is chosen to be $[0, p^{\Theta(1)}]$. Such a choice leads to efficient implementation of the hash function: convolution ($\pazocal{O}(n\,log\,n)$), addition of vectors ($\pazocal{O}(n\,log\,n)$), and so on.

The generalised knapsack function is linear:
$f_{\mathbf{a}}(\mathbf{d}) + f_{\mathbf{a}}(\mathbf{d}^{\prime}) =
f_{\mathbf{a}}(\mathbf{d} + \mathbf{d}^{\prime})$. For
$f_{\mathbf{a}}(\mathbf{d}^{\prime}) = 0$, collision is detected.
Thus given a fixed $\mathbf{d} \in S$, we need to find
$\mathbf{d}^{\prime}$ such that the condition is satisfied. Note
however a condition on $\mathbf{d}$: $\parallel \mathbf{d}
\parallel_{\infty} < p^{\Theta(1)}$, or an upper bound on the
infinite norm of $\mathbf{d}$ giving the following relation:

$$\parallel \mathbf{d} \parallel \leq \sqrt{n} \parallel \mathbf{d} \parallel_{\infty} <  p^{\Theta(1)}$$

and $\parallel \mathbf{d}^{\prime}\parallel_{\infty} = 1$, thereby
implying we are trying to find relatively short vectors. Such
special constraints on $S$ can prevent such an attack. For an
efficient hash function, security parameter $n$ is chosen as prime
and $\Phi(\alpha) = \alpha - 1$; the hash function has outputs
compressed by factors of $\frac{m\, log\, (p^{\Theta(1)})}{log\,
p}$. The security of the above hash function is established by worst
case reduction from an incremental version of \textit{subSVP} where
$\zeta = \eta_{\epsilon}$ to finding collisions ($\eta_{\epsilon}$
is described as the the lattice function tasked with finding the
value of the \textit{smoothing} parameter for the given lattice, or
informally, finding the radius of the Gaussian noise whose uniform
samples when added to the lattice can transform it into a
\textit{near} uniform distribution, i.e. \textit{loss of
discreteness} due to added \textit{blur}). Hardness is therefore
established by further reduction from \textit{SVP} to the above
chosen cyclotomic version implying hardness is based on solutions to
\textit{SVP} in the worst case. For instance, for \textit{prime} n,
$m\,=\,\Theta(log\,n)$ and $p\,=\,n^{2.5 + \Theta(1)}$, finding
collisions is as hard as solving \textit{SVP} up to factors of
$n.poly(log\,n)$ with non-negligible probability.


Despite the security guarantee, there exist trade-offs between the provable security of a certain hash function family and its efficient implementation. SWIFFT is one such proposal that is provably secure as well as efficient to implement. First introduced in Lyubashevsky \textit{et. al.}\cite{CRHF_Rosen2008} as an extension to the works of Micciancio\cite{CRHF_Micciancio2002_compact_knapsacks}, SWIFFT is a collision resistant hash function with security based on the worst-case problems in lattices corresponding to ideals in $\mathbb{Z}_{p}[x]/\langle x^{n} + 1 \rangle$ (for variable $x$) with comparable performance to ad-hoc hash functions in use today. SWIFFT arranges the input of binary strings of length $mn$ as a block matrix $\in \{ 0,\, 1\}^{m \times n}$, for suitable choices of security parameters $m$ and $n$. Efficient implementation of this scheme is achieved by using column Fast Fourier transform on the aforementioned matrix. The construction of the function ensures computation is parallelizable and connected to well-studied cryptographic problems. Formally, the function is described as $h_{\mathbf{a}}(\mathbf{x})\, = \, \sum_{i=1}^{n} a_{i}x_{i}$ where $a_{i}$ is sampled uniformly at random from the ring $\pazocal{R} \, = \,\mathbb{Z}_{p}[x]/\langle x^{n} + 1 \rangle$ and $x_{i}$ are sampled from ideals in $\pazocal{R}$. Use of FFT eases implementation of polynomial products implicit in the function definition. Security considerations are based on the irreducible nature of $x^{n} + 1$ over the defined ring, fact that $p$ should be prime and $p - 1$ should be a multiple of $2n$ (leads to optimised running time for FFT), and uniform distribution of $a_{i}$ over the ring. Further improvements include storing initial computation of FFT on binary vectors in lookup tables, and taking better advantage of parallelism offered by modern processors.


\section{Recent Advancements}

\subsection{Programmable Hash Funtions}

The work of Zhang \cite{CRHF_Zhang2016} proposed a recent construction- \textit{programmable hash functions}- originally introduced by Hofheinz and Kiltz \cite{CRHF_Hofheinz2008} achieving short signature schemes over bilinear maps. Other works on PHFs include Yamada \textit{et. al.} \cite{CRHF_Yamada2012} which significantly reduce the size of the public key used in Hofheinz \cite{CRHF_Hofheinz2008} while maintaining short signatures as in the original construction, Hanaoka \textit{et. al.}\cite{CRHF_Hanaoka2012} which derives a lower bound on the hash key size and discuss the impossibility of existence of algebraic PHFs in prime order groups for any $n \in \mathbb{Z}$, Hofheinz \cite{CRHF_Hofheinz2012}, Freire \textit{et. al.} \cite{CRHF_Freire2013} which treat PHFs in multi-linear settings and in noisy multi-linear maps, Catalano \textit{et. al.} \cite{CRHF_Catalano2015} which introduces asymmetric PHFs that include two main new ideas: publicly computable isomorphic copy of the function and embedding a separate pseudo-random value as the output of the function for constructing signatures with shorter public keys. Most of these constructions are based on groups where the \textit{discrete logarithm} problem (DL) is hard.

Formally, PHFs are keyed group hash functions over a finite group $\mathbb{G}$ that behave in statistically indistinguishable ways based on the mode of key generation: \textit{normal} mode such that $h:\, \{0,1\}^{m} \rightarrow \mathbb{G}$ and a \textit{trapdoor} mode where additional information $a, \, b \in \mathbb{Z}$ is obtained such that for pre-fixed $g, \, h \in \mathbb{G}$, $h:\, \{0,1\}^{m} = g^{a}.h^{b}$. Given the hardness of the DL problem, it is straightforward to note the hardness of inversing this additional trapdoor mode information outputted.

Zhang \textit{et. al.} \cite{CRHF_Zhang2016} derives lattice-based PHFs that are collision resistant under \textit{inhomogeneous small integer solutions} or ISIS hardness assumption. Such hash functions are no longer group hash functions, but retain the statistically indistinguishable operations under the mode of key generation. On lattices, the normal operation of the hash function is given as $h(\mathbf{x}) \, \in \, \mathbb{Z}^{n \times m}_{q}$ for usual $n,\, m,\, q$ in the definition of lattices. While the trapdoor operation involves outputting trapdoor information $\mathbf{A}$ and $\mathbf{B}$ such that for any \textit{generators} $\mathbf{P} \in \mathbb{Z}^{n \times p}_{q}$ and $\mathbf{Q} \in \mathbb{Z}^{n \times m}_{q}$, $h(x)\,=\,\mathbf{P} \mathbf{A} \,+\, \mathbf{B} \mathbf{Q}$. Under dimensionality checks, it is straightforward to see $\mathbf{A}\,\in\,\mathbb{Z}_{p}^{p \times m}$ and $\mathbf{B}\,\in\,\mathbb{Z}^{n \times n}_{q}$. The generator $\mathbf{P}$ embeds the ISIS problem while the generator $\mathbf{Q}$ embeds a variant of short vector search problem, leading to provable hardness of the described hash function family.

\subsection{On Gr\"{o}bner bases and Ideal lattices}

Francis \textit{et. al} \cite{CRHF_Francis2018} developed a construction of hash function based on Gr\"{o}bner bases and ideal lattices. The hardness of the construction is based on the \textit{Smallest Polynomial Problem- SPP}- for multivariate ideal lattices. In the univariate case, \textit{SPP} is reducible to \textit{Shortest Conjugate Problem- SCP}- whose hardness is based on the isomorphism of number fields. In the multivariate case however, the authors introduce another problem named \textit{Smallest Substitution Problem- SSP} whose hardness is based on determining if two functional fields are isomorphic, and \textit{SCP} can be polynomially reduced to SSP, thereby establishing the hardness for SPP.

The generalized hash functions based on multivariate ideal lattices are defined as $\pazocal{H}(\pazocal{R}, D, m)$ where $\pazocal{R}$ is the ring $\mathbb{Z}_{p}[x_{1}, x_{2}, ..., x_{n}]/I$ such that $p$ is of the order $n^{2}$. $D$ is a properly chosen subset of $\pazocal{R}$ having $\{g \in \pazocal{R}\}$ such that the norm of $g$ with respect to the ideal $I$ is upper bounded by a parameter $d$. The security of the generated hash functions requires the ideal \textit{I} in a finitely generated residue class polynomial ring $\mathbb{Z}[x_{1}, x_{2}, ..., x_{n}]/I$ to be a prime ideal, which forces the generated multivariate lattice to be full rank or \textit{lattice rank = lattice dimension} (this is exactly like the full rank requirement of univariate lattices that aids in preventing development of collision attacks against primitives developed on such lattices). There are other additional conditions for which we refer the reader to the original paper. For the parameter $m \geq \frac{log p}{log 2d}$, the constructed hash function has collisions, and any algorithm to find such collisions is equivalent to solving approximate-\textit{SPP}. Earlier discussion on reductions of worst case instances of these problems establishes the security of such constructions.


\subsection{Chameleon Hash Functions}

A recent construction by Mohassel \textit{et.al.}\cite{CRHF_Mohassel2011}- Chameleon hash functions- are collision resistant hash functions dependent upon certain probability distributions and having a pair of keys: public key and private (trapdoor) key. A chameleon hash function satisfies three properties: it is computable using the public key, it is collision resistant if trapdoor is not known, and collisions are easy to find if trapdoor information is known.

Generalised chameleon hash functions are sets of three algorithms
(say $Gen$, $h$, and $h^{-1}$). $Gen$ generates the pair of keys:
the public key $k_{public}$ and the trapdoor $k_{trap}$. $h$
converts a given message $m$ to its hash, i.e. output hash = $h(m,\,
k_{public}, r)$ where $r \in S$ and $r$ is drawn from $P$ where $P$
is some probability distribution over some set $S$. Finally,
$h^{-1}$ outputs $r^{\prime}$ over $S$ given $h^{-1}(m, m^{\prime},
k_{trap}, r)$ such that for distinct messages $m$ and $m^{\prime}$
and $r \in S$ as discussed before, $h(m, k_{public}, r) =
h(m^{\prime}, k_{public}, r^{\prime})$.

Lattice based chameleon hash functions can be constructed in similar ways. For the security parameter $k$, define $\mathbf{A} \in \mathbb{Z}_{q}^{k \times m_{1}}$ and $\mathbf{B} \in \mathbb{Z}_{q}^{k \times m_{2}}$ as well as the message domain $M = \{\mathbf{x} \in \mathbb{Z}_{q}^{m_{1}}: \parallel \mathbf{x} \parallel_{2} \leq \beta_{1}\}$ and randomness domain (discrete Gaussian) $R = \{\mathbf{x} \in \mathbb{Z}_{q}^{m_{2}}: \parallel \mathbf{x} \parallel_{2} \leq \beta_{2}\}$. $\beta_{1}$ and $\beta_{2}$ are parameters that directly affect the length of such domains. The chameleon hash function is defined as $h(\mathbf{m}, \mathbf{r}) = \mathbf{A} \mathbf{m} + \mathbf{B} \mathbf{r}$ where $\mathbf{m} \in M$ and $\mathbf{r} \in R$ and output $\mathbf{y} \in Z_{p}^{k}$. The hardness of $h(m, r)$ is based on assumed hardness of $SIS$ (short integer solutions) in the worst case (which in turn depends on $SVP$ (shortest vector problem) on arbitrary lattices). Trapdoor information is a short basis for the lattice whose parity check matrix is $\mathbf{B}$ (used in $h(\mathbf{m}, \mathbf{r})$). Good choice of parameters include $q$ as odd prime and \textit{= poly(k)}. $m_{1}$ and $m_{2}$ (dimensions of subspaces from which $\mathbf{A}$ and $\mathbf{B}$ are sampled), must be of the order $\pazocal{O}(k\, log\, q)$.


\section{Comparative analysis}

Table \ref{qrbt_Tab2} gives a comparative analysis of all the schemes discussed in this review. Key for table- CR: collision resistant, SVP: shortest vector problem, CRP: covering radius problem, SIVP: shortest independent vectors problem, GDD: guaranteed distance decoding problem, SPP: shortest polynomial problem (we refer the reader to Lyubashevsky\cite{CRHF_Lyubashevsky2006} for exact definition of $\mathcal{\epsilon}$).

\begin{table}[H]
\renewcommand{\arraystretch}{1.3}
\caption{Comparative analysis of the various hash function construction discussed in the paper. }
\label{qrbt_Tab2}
\centering
\begin{tabular}{|c||c||c||c||c|}
\hline
\textbf{Ref.} & \textbf{Security} & \textbf{Lattice used}& \textbf{Hardness assumption} & \textbf{Approximation factor $\gamma$} \\
\hline
\cite{CRHF_Ajtai1996} & One-way & Integer lattice & SVP & $n^{c}; \, c > 8$ \\
\hline
\cite{CRHF_Goldreich1996} & One-way and CR & Integer lattice & SVP & $n^{c}; \, c > 8$ \\
\hline

\cite{CRHF_Cai1997} & One-way and CR & Integer lattice & SVP & $n^{4 + \epsilon}$ \\

\hline

\cite{CRHF_Micciancio2002} & One-way and CR & Integer lattice & SVP & $n^{3 + \epsilon}$ \\

\hline
\cite{CRHF_Micciancio2004} & One-way and CR & Integer lattice & SVP, SIVP, CRP & $\Tilde{\pazocal{O}}(n)$ \\
\hline
\cite{CRHF_Regev} & One-way and CR & Integer lattice & unique-SVP & $\pazocal{O}(n^{1.5})$ \\

\hline
\cite{CRHF_Micciancio2002_compact_knapsacks} & One-way & Cyclic lattice & GDD & $n^{1 + \epsilon}$ \\

\hline

\cite{CRHF_Lyubashevsky2006} & One-way and CR & Cyclic lattice & SPP & $\Tilde{\pazocal{O}}(n) \mathcal{\epsilon}^{2}$ \\
\hline

\cite{CRHF_Peikert2006} & One-way and CR & Cyclic lattice & SVP & $\Tilde{\pazocal{O}}(n) $ \\


\hline
\end{tabular}
\end{table}


\section{Conclusion}

The research community in mathematical cryptography has successfully evaded the presumed threat from quantum devices, even before the latter are constructed to a level where such threats are realised. One such cryptographic primitive- collision resistant hash functions on lattices- is described in this review. Several constructions are presented, and their advantages and disadvantages discussed. These provide a base for advancements both in the implementation of hash functions as well as their integration in richer cryptographic primitives such as digital signatures and encryption schemes. In the research timeline, these works also paved their way into our understanding of computational problems by coming up with new mathematical techniques for reductions, suggesting ways for manipulation of lattices for establishing security, providing tighter bounds on approximations of lattice based problems, and enriching the independent field of lattices in general. Several of these ideas manifested themselves in many later works on lattices and on cryptography.

%\bibliographystyle{elsarticle-num}
% \bibliographystyle{plain}
% \bibliography{2paka}
\begin{thebibliography}{9}

\bibitem{CRHF_Ajtai1996} Ajtai, M. 1996. Generating hard instances of lattice problems. In ECCCTR: Electronic Colloquium on Computational Complexity, technical reports.

\bibitem{LLL}Lenstra, A.K., Lenstra, H.W. and Lov{\` a}sz, L. Factoring polynomials with rational coefficients. Math. Ann. 261, 515-534 (1982).https://doi.org/10.1007/BF01457454

\bibitem{CRHF_Goldwasser} Micciancio, D, and Goldwasser, Shafi. Complexity of Lattice Problems: A Cryptographic Perspective. Springer.

\bibitem{CRHF_BBD}D. Bernstein, J Buchmann, and E. Dahmen, Post-Quantum Cryptograhy. Springer. 2000

\bibitem{CRHF_Goldreich1996}Goldreich, O., Goldwasser, S., and Halevi, S.: Collision-free hashing from lattice problems. Technical Report TR96-056, Electronic Colloquium on Computational
Complexity (ECCC) (1996).

\bibitem{CRHF_Cai1997} Cai, J.Y. and Nerurkar, A.: An improved worst-case to average-case connection for lattice problems. In Proc. 38th IEEE Symp. on Found. of Comp. Science, pages 468-477 (1997).

\bibitem{CRHF_Cai1999} Cai, J.-Y. 1999. Applications of a new transference theorem to Ajtai’s connection factor. In Proceedings of the 14th IEEE Conference on Computational Complexity. IEEE Computer Society Press, Los Alamitos, Calif., pp. 205-214

\bibitem{CRHF_Micciancio2002}Micciancio, D.: Improved cryptographic hash functions with worst-case/averagecase connection. In Proc. 34th ACM Symp. on Theory of Computing (STOC), pages 609-618 (2002).

\bibitem{CRHF_Micciancio2004}Micciancio, D. and Regev, O.: Worst-case to average-case reductions based on Gaussian measures. In Proc. 45th Annual IEEE Symp. on Foundations of Computer Science (FOCS), pages 372-381 (2004).

\bibitem{CRHF_Micciancio2002_compact_knapsacks}Micciancio, D.: Generalized compact knapsacks, cyclic lattices, and efficient one- way functions from worst-case complexity assumptions. Computational Complexity, 16(4):365-411 (2007). Preliminary versions in FOCS 2002 and ECCC TR04-095.

\bibitem{CRHF_Lyubashevsky2006}Lyubashevsky, V. and Micciancio, D.: Generalized compact knapsacks are collision resistant. In 33rd International Colloquium on Automata, Languages and Programming (ICALP) (2006).

\bibitem{CRHF_Peikert2006}Peikert, C. and Rosen, A.: Efficient collision-resistant hashing from worst-case assumptions on cyclic lattices. In 3rd Theory of Cryptography Conference (TCC), pages 145-166 (2006).

\bibitem{CRHF_Rosen2008}Lyubashevsky, V., Micciancio, D., Peikert, C., and Rosen, A.: SWIFFT: a modest proposal for FFT hashing. In FSE 2008 (2008).

\bibitem{CRHF_Regev} O. Regev, New Lattice-based cryptographic constructions. Journal of the ACM, \textbf{51} 6.



\bibitem{CRHF_Impagliazzo1996} Impagliazzo, R., and Naor, M. 1996. Efficient cryptographic schemes provably as secure as subset sum. J. Crypt. 9, 4, 199-216.

\bibitem{CRHF_Ajtai1997} Ajtai, M., AND Dwork, C. 1997. A public-key cryptosystem with worst-case/average-case equiva- lence. In Proceedings of the 29th ACM Symposium on Theory of Computing. ACM , New York, 284- 293.

\bibitem{CRHF_Banaszczyk1993}Banaszczyk, W. 1993. New bounds in some transference theorems in the geometry of numbers. Math. Annal. 296, 4, 625-635.

\bibitem{CRHF_Zhang2016} Zhang J., Chen Y., Zhang Z. (2016) Programmable Hash Functions from Lattices: Short Signatures and IBEs with Small Key Sizes. In: Robshaw M., Katz J. (eds) Advances in Cryptology - CRYPTO 2016. CRYPTO 2016. Lecture Notes in Computer Science, vol 9816. Springer, Berlin, Heidelberg.



\bibitem{CRHF_Hofheinz2008}Hofheinz, D., Kiltz, E.: Programmable hash functions and their applications. In: Wagner, D. (ed.) CRYPTO 2008, LNCS, vol. 5157, pp. 21-38. Springer (2008)

\bibitem{CRHF_Yamada2012}Yamada, S., Hanaoka, G., Kunihiro, N.: Two-dimensional representation of cover free families and its applications: Short signatures and more. In: Dunkelman, O. (ed.) CT-RSA 2012, LNCS, vol. 7178, pp. 260-277. Springer (2012)

\bibitem{CRHF_Hanaoka2012} Hanaoka,G.,Matsuda,T.,Schuldt,J.:On the impossibility of constructing efficient key encapsulation and programmable hash functions in prime order groups. In: Safavi-Naini, R., Canetti, R. (eds.) CRYPTO 2012, LNCS, vol. 7417, pp. 812-831.
Springer (2012)

\bibitem{CRHF_Hofheinz2012} Hofheinz, D., Kiltz, E.: Programmable hash functions and their applications. Journal of Cryptology 25(3), 484-527 (2012)

\bibitem{CRHF_Freire2013} Freire, E., Hofheinz, D., Paterson, K., Striecks, C.: Programmable hash functions in the multilinear setting. In: Canetti, R., Garay, J. (eds.) CRYPTO 2013, LNCS, vol. 8042, pp. 513-530. Springer (2013)

\bibitem{CRHF_Catalano2015} Catalano, D., Fiore, D., Nizzardo, L.: Programmable hash functions go private: Constructions and applications to (homomorphic) signatures with shorter public keys. In: Gennaro, R., Robshaw, M. (eds.) CRYPTO 2015, LNCS, vol. 9216, pp. 254-274. Springer (2015)

\bibitem{CRHF_Lyubashevsky2009Shamir} Lyubashevsky V. (2009) Fiat-Shamir with Aborts: Applications to Lattice and Factoring-Based Signatures. In: Matsui M. (eds) Advances in Cryptology - ASIACRYPT 2009. ASIACRYPT 2009. Lecture Notes in Computer Science, vol 5912. Springer, Berlin, Heidelberg

\bibitem{CRHF_Shor1997} P. Shor. Polynomial-time algorithms for prime factorization and discrete logarithms on a quantum computer. SIAM J. Comput., 26(5):1484–1509, 1997.


\bibitem{CRHF_Francis2018} Francis, Maria and Dukkipati, Ambedkar (2018) On ideal lattices, Grobner bases and generalized hash functions. In: JOURNAL OF ALGEBRA AND ITS APPLICATIONS, 17 (6).

\bibitem{CRHF_Mohassel2011} Mohassel P. (2011) One-Time Signatures and Chameleon Hash Functions. In: Biryukov A., Gong G., Stinson D.R. (eds) Selected Areas in Cryptography. SAC 2010. Lecture Notes in Computer Science, vol 6544. Springer, Berlin, Heidelberg


\bibitem{CRHF_Joux1994}A. Joux and L. Granboulan. A practical attack against knapsack based hash functions. In EURO-CRYPT'94, pages 58-66, 1994.

\bibitem{CRHF_Shamir1984_MH} A. Shamir. A polynomial time algorithm for breaking the basic Merkle-Hellman cryptosystem. IEEE Transactions on Information Theory, IT-30(5):699-704, 1984.

\bibitem{CRHF_Vaudenay2001}S. Vaudenay. Cryptanalysis of the Chor-Rivest cryptosystem. Journal of Cryptology, 14(2):87-100, 2001.

\bibitem{CRHF_Micciancio_perfect_lattices} D. Micciancio. Almost perfect lattices, the covering radius problem, and applications to Ajtai's connection factor. SIAM Journal on Computing, 34(1):118–169, 2004. Preliminary version in STOC 2002.
\end{thebibliography}
\end{document}
